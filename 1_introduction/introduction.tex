% -*- root: ../thesis.tex -*-
%!TEX root = ../thesis.tex
% ******************************* Thesis Chapter 1 ****************************

% ----------------------------------------------------------------------
%: ----------------------- introduction content ----------------------- 
% ----------------------------------------------------------------------

The realm of connected digital services that companies are offering has grown in the last decades to a point where they are essential for our society to function. Although it has brought many advantages, a big problem with this development is the way personal data is collected and used. In particular, the business model of many tech companies is to collect and sell data.
For example, Meta \footnote{\url{https://www.meta.com}}, the company behind Facebook, is using personal data, meaning data that is linked to a natural person, such as age, gender, interests, and many more to advertisers. This model is called personalized advertising \cite{tucker_social_2014}. 

To provide resilient, scalable, and easy-to-manage applications, many companies are using microservice architectures today. Netflix for example uses hundreds of microservices in their infrastructure\footnote{\url{https://www.nginx.com/blog/microservices-at-netflix-architectural-best-practices/}}. Although splitting the application into different services has advantages, one disadvantage is keeping track of where personal data are used or stored and for what purpose. This is especially important because of the strong requirements specified by regulatory frameworks, such as the GDPR. For example, \parencite[Art. 13]{noauthor_general_2016} requires a company to disclose information about which personal data are collected and for what purpose. 
To solve this issue there are many transparency-enhancing technologies available, which help by inspecting the dataflow inside a cluster. For example, Google Cloud Data Loss Prevention\footnote{\url{https://cloud.google.com/dlp}}.
Also, more generic privacy-enhancing technologies exist, that embody the basic data protection principles. Google Differential Privacy, for example, encourages the anonymization of personal data\footnote{\url{https://github.com/google/differential-privacy}}.
However, overall, the usage of all of these technologies is pretty low. \\

Particularly relevant in this context are the following three groups of technical measures:\\

\textbf{Data loss prevention (DLP)} describes a whole suite of technologies that detect potential data breaches and/or identify security risks, like for example unencrypted passwords, etc. The latter is achieved by scanning data sources like storage buckets, databases, etc. for specific information. \cite{zhang_what_2020} From technology to technology the information, which is searched for can vary. In most cases, its personal data or passwords. This feature is called data identification. \cite{kim_sensitive_2020} Many DLP technologies support data identification directly in their API. The result often contains a list of findings, which is supported by a so-called data type (e.g., email, credit card number) that abstracts the type of data found. \footnote{\url{https://cloud.google.com/dlp/docs/reference/rpc/google.privacy.dlp.v2?hl=de\#google.privacy.dlp.v2.Finding}}\textsuperscript{,}\footnote{\url{https://docs.aws.amazon.com/macie/latest/APIReference/findings-describe.html}} Some DLPs also have a risk analysis feature that calculates privacy guarantees such as k-anonymity \cite{sweeney_k-anonymity_2002} or l-diversity \cite{machanavajjhala_l_2007}.\footnote{\url{https://cloud.google.com/dlp/docs/reference/rpc/google.privacy.dlp.v2?hl=de\#analyzedatasourceriskdetails}} Some examples include Google Cloud DLP, AWS Macie\footnote{\url{https://aws.amazon.com/de/macie/}} from industry, and Teiresias from academia \cite{grunewald_teiresias_2022}.\\

\textbf{Static Code analysis} describes the inspection of source code for many objectives. \cite{novak_taxonomy_2010} Some tools focus on security, e.g., finding possible SQL injections, others focus on compliance, e.g., validating a code style. Static code analysis is done before compilation/deployment, e.g., by a continuous integration tool. Generally said code analysis can be used as a privacy-enhancing technology, by inspecting possible security flaws. \\

\textbf{Policy languages} are really broadly used and defined for many sorts of targets. Possible types of languages include access control, rights, privacy preferences, web services, etc. TILT is a policy language, that represents transparency information according to the GDPR. \cite{noauthor_review_nodate}
There are many other policy languages, for example, LPL\footnote{\url{https://lpl.unifr.ch/lpl/index.html}}, P3P\footnote{\url{https://www.w3.org/P3P/}}, and XACML\footnote{\url{https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=xacml}}.


