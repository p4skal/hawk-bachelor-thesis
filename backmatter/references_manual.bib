
@article{grunewald_teiresias_2022,
	title = {Teiresias: {Scalable} {Discovery} and {Continuous} {Inventory} of {Personal} {Data} at {Rest} in {Cloud} {Native} {Systems}},
	author = {Grünewald, Elias and Schurbert, Leonard},
	year = {2022},
}

@misc{noauthor_general_2016,
	title = {General {Data} {Protection} {Regulation} ({EU}) no 2016/679},
	url = {https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679},
	publisher = {The European Parliament},
	year = {2016},
}

@misc{noauthor_review_nodate,
	title = {Review of {Policy} {Languages} and {Frameworks}},
	url = {https://www.w3.org/Policy/pling/wiki/PolicyLangReview},
	publisher = {Policy Languages Interest Group},
}

@misc{grunewald_tilt_2020,
	title = {{TILT}: {A} {GDPR}-{Aligned} {Transparency} {Information} {Language} and {Toolkit} for {Practical} {Privacy} {Engineering}},
	shorttitle = {{TILT}},
	url = {http://arxiv.org/abs/2012.10431},
	abstract = {In this paper, we present TILT, a transparency information language and toolkit explicitly designed to represent and process transparency information in line with the requirements of the GDPR and allowing for a more automated and adaptive use of such information than established, legalese data protection policies do. We provide a detailed analysis of transparency obligations from the GDPR to identify the expressiveness required for a formal transparency language intended to meet respective legal requirements. In addition, we identify a set of further, non-functional requirements that need to be met to foster practical adoption in real-world (web) information systems engineering. On this basis, we specify our formal language and present a respective, fully implemented toolkit around it. We then evaluate the practical applicability of our language and toolkit and demonstrate the additional prospects it unlocks through two different use cases: a) the inter-organizational analysis of personal data-related practices allowing, for instance, to uncover data sharing networks based on explicitly announced transparency information and b) the presentation of formally represented transparency information to users through novel, more comprehensible, and potentially adaptive user interfaces, heightening data subjects' actual informedness about data-related practices and, thus, their sovereignty. Altogether, our transparency information language and toolkit allow - differently from previous work - to express transparency information in line with actual legal requirements and practices of modern (web) information systems engineering and thereby pave the way for a multitude of novel possibilities to heighten transparency and user sovereignty in practice.},
	urldate = {2022-07-30},
	publisher = {arXiv},
	author = {Grünewald, Elias and Pallas, Frank},
	month = dec,
	year = {2020},
	note = {arXiv:2012.10431 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Cryptography and Security, Computer Science - Formal Languages and Automata Theory, Computer Science - Software Engineering, D.2, E.2, H.3, H.5, K.4, K.5},
	file = {arXiv Fulltext PDF:/Users/paskal/Zotero/storage/6CV2WHQH/Grünewald and Pallas - 2020 - TILT A GDPR-Aligned Transparency Information Lang.pdf:application/pdf;arXiv.org Snapshot:/Users/paskal/Zotero/storage/3RKBBI9U/2012.html:text/html},
}

@article{zhang_what_2020,
	title = {What is {Data} loss prevention ({DLP})?},
	url = {https://digitalguardian.com/blog/what-data-loss-prevention-dlp-definition-data-loss-prevention},
	author = {Zhang, Ellen},
	year = {2020},
}

@inproceedings{kim_sensitive_2020,
	address = {Sanya China},
	title = {Sensitive {Data} {Identification} in {Structured} {Data} through {GenNER} {Model} based on {Text} {Generation} and {NER}},
	isbn = {978-1-4503-7771-3},
	url = {https://dl.acm.org/doi/10.1145/3398329.3398335},
	doi = {10.1145/3398329.3398335},
	language = {en},
	urldate = {2022-08-07},
	booktitle = {Proceedings of the 2020 {International} {Conference} on {Computing}, {Networks} and {Internet} of {Things}},
	publisher = {ACM},
	author = {Kim, Gun-woo and Lee, Dong-ho},
	month = apr,
	year = {2020},
	pages = {36--40},
}

@inproceedings{novak_taxonomy_2010,
	title = {Taxonomy of static code analysis tools},
	author = {Novak, Jernej and Krajnc, Andrej and Žontar, Rok},
	year = {2010},
}

@article{sweeney_k-anonymity_2002,
	title = {K-{Anonymity}: {A} model for protecting privacy},
	volume = {10},
	issn = {0218-4885, 1793-6411},
	shorttitle = {k-{ANONYMITY}},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218488502001648},
	doi = {10.1142/S0218488502001648},
	abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, μ-Argus and k-Similar provide guarantees of privacy protection.},
	language = {en},
	number = {05},
	urldate = {2022-08-09},
	journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	author = {Sweeney, Latanya},
	month = oct,
	year = {2002},
	pages = {557--570},
}

@article{machanavajjhala_l_2007,
	title = {\textit{{L}} -diversity: {Privacy} beyond \textit{k} -anonymity},
	volume = {1},
	issn = {1556-4681, 1556-472X},
	shorttitle = {\textit{{L}} -diversity},
	url = {https://dl.acm.org/doi/10.1145/1217299.1217302},
	doi = {10.1145/1217299.1217302},
	abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called
              k
              -anonymity has gained popularity. In a
              k
              -anonymized dataset, each record is indistinguishable from at least
              k
              − 1 other records with respect to certain identifying attributes.
            
            
              In this article, we show using two simple attacks that a
              k
              -anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that
              k
              -anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called ℓ-diversity that can defend against such attacks. In addition to building a formal foundation for ℓ-diversity, we show in an experimental evaluation that ℓ-diversity is practical and can be implemented efficiently.},
	language = {en},
	number = {1},
	urldate = {2022-08-09},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
	month = mar,
	year = {2007},
	pages = {3},
}
