% -*- root: ../thesis.tex -*-
%!TEX root = ../thesis.tex
% ******************************* Thesis Chapter 6 ****************************


% ----------------------- paths to graphics ------------------------

% change according to folder and file names
\graphicspath{{6/figures/}}
% ----------------------- contents from here ------------------------

To implement such software as stated in the requirements section, the Hawk framework will be extended. Hawk is a framework that provides an abstraction about protocol-independent traffic analysis. It also features a currently very limited visualization of the results. There are also modules that provide extra toolings, like a release integration or a CI feature.
Although the method of the Hawk framework is novel, one of its biggest limitations is traffic analysis at its core. So the solution is to extend Hawk to support different inputs besides traffic analysis. New inputs could be data loss prevention, code analysis, or different policy languages. Also, a better API is needed to enable the above-mentioned requirements.


As described in the context, there are many privacy-enhancing technologies available to implement. Since the scope to implement all mentioned technology categories would be too big, this implementation will only focus on one. Data loss prevention offers the most promising features in relation to its comparably simple implementation. This thesis focuses on expanding Hawk, as mentioned above, and adding data loss prevention as an input besides traffic analysis. Since data loss prevention is a lax-defined category of technologies, we only consider DLP implementations that support the data inspection feature.
For this reason, the DLP input abstraction focuses on data identification and risk analysis. The new Hawk Core will also implement the cluster detection module, as defined in functional requirement 2. This module will be based on a cluster/environment detection mechanism to know which services exist and to resolve specific name references present in the input abstraction schema. This is cluster-aware to fulfill the non-functional requirement 3. The module information, together with the results of the present inputs, is then exposed in a REST API, according to functional requirement 3.

To illustrate this, we take a simple user registration application, in which the user can register with his name, email, address, etc. as an example. A Front-End application provides an HTML form, which sends a JSON HTTP request containing the data to the Back-End. With the already existing traffic analysis input, it is possible to track that at a particular time, an HTTP request from the Front-End to the Back-End was sent, containing references to the mentioned data. Now, with the DLP input in place, it is possible to scan the database of the Back-End and identify what user data it has stored. With the new cluster detection mechanism, it would also be possible to connect both results and refer to them in a report. The more inputs/outputs are implemented, the more insight into the system is possible.


% ---------------------------------------------------------------------------
%: ----------------------- end of thesis sub-document ------------------------
% ---------------------------------------------------------------------------

